\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx, color}
\setlength{\topmargin}{-1in}
\linespread{1}
\usepackage[T1]{fontenc}
\usepackage{kpfonts,baskervald}
\usepackage{lipsum}

\title{How do we sort these goddamn robots: Label availability changes object classification method}
\author{Cody Kommers, Maddie Snyder}
\date{December 2016}

\begin{document}
\maketitle

\noindent How do we sort objects into categories in the world? Typically, in the mind, objects are inextricably tied to their word labels. Seeing a tree evokes the word `tree', seeing your friend evokes their name, etc. 

\vspace{.2in}

\noindent Here we build a model of image categorization in which the categorization of objects is dependent on the labeled examples available during learning. If there is one labeled object presented, generalization of the label category will occur across objects that are most similar along the dimension of lowest visual variance. If there is more than one object labeled, then generalization will occur across the dimension of highest visual variance. 

\vspace{.2in}

\noindent The task is for subjects to decide if a robot came from the FEP machine or not (is it a FEP or not?). The model reflects this by generating robots whose identities can be determined by sorting according to the dimension of highest variance, but not by sorting according to the dimension of lowest variance. The model is as follows: generate a bottom according to a normal distribution with high variance, then pair that bottom with a top generated from one of two other normal distributions each with variances that are lower than the bottom dimension variance but are not the same. 

\vspace{.2in}

\noindent Generative model parameters:
\begin{itemize}
	\item Robot bottom length $\sim N(\mu_1, \sigma_1)$ (Dimension that can diagnose robot's machine origin)
	\item Robot top length $\sim N(\mu_2, \sigma_2)$ or $\sim N(\mu_3, \sigma_3)$ (Drawn from one of two distributions to fool the subject)
	\item **Head length - Body Length = Diff $\sim N(\mu_1 - top\mu, \sigma_1 + top\sigma)$ (Diff)
	\item Uniform distance between Head and Body
	\item $\sigma_1 << \sigma_2$
\end{itemize}

\noindent Schema: 

\noindent (1.1) Robots generated according to model defined above

\noindent (1.2) Subjects presented with a variety of robots with one robot labeled "FEP"

\noindent (1.3) Subjects presented with another labeled robot that was previously unlabeled and are asked to judge if it's a "FEP"

\noindent (2.1) Subjects presented with a variety of robots with three robots labeled "FEP"

\noindent (2.2) Subjects presented with another labeled robot that was previously unlabeled and are asked to judge if it's a "FEP"

\vspace{0.2in}

\noindent **Confounding factor: Subjects may judge ``fepness'' by the difference between the lengths of the head and the body. BUT this might actually be the dimension of lowest variance, visually.

\vspace{0.2in}

\noindent Diff $\sim FoldedNormal(\mu,\sigma)$ where $\mu_Y = \sigma \sqrt{\frac{2}{\pi}}e^{(-\mu^2/2\sigma^2)} + \mu (1-2\Phi(\frac{-\mu}{\sigma}))$ and $\sigma_Y = \mu^2 + \sigma^2 - \mu_Y ^2$

\noindent What is the "variance" of color?

\noindent What is the "variance" of pattern?

\noindent Would the effect of categorizing by difference between Head and Body length be eliminated if you shortened the presentation time?

\vspace{0.5in}

\noindent TODO:
\begin{itemize}
	\item Modify the generative model such that there are actually two machines that generate robots whose identity can't be diagnosed by the dimension of least variance. (DONE)
	\item Convert generative robot model to javascript (DONE)
	\item Learn JsPsych to create experiment (DONE)
	\item Generate the robots on the fly within the JsPsych code, maybe create a jsPsych plugin?
\end{itemize}

\vspace{0.5in}
\noindent Important Links
\begin{itemize}
	\item JsPsych: http://docs.jspsych.org/tutorials/rt-task/\#part-9-displaying-the-data
	\item ProbMods Playspace: https://probmods.org/v2/exercises/02-generative-models.html
\end{itemize}

\newpage

\noindent 2/2/2017

\vspace{.2in}

\noindent Generative Model Development Process:

1D clustering --> 1D labeling --> 2D clustering --> 2D labeling

\vspace{.2in}

1D clustering model informed by Gibson 2013.

Generate examples from a mixture of two Gaussians 

\end{document}